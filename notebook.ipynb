{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa02648-9eae-45ba-893f-88440e8e4235",
   "metadata": {},
   "source": [
    "![clothing_classification](clothing_classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a988c-1095-485a-a88c-002400a872be",
   "metadata": {},
   "source": [
    "Fashion Forward is a new AI-based e-commerce clothing retailer.\n",
    "They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n",
    "\n",
    "As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8065b7-84fc-4376-afef-6db731dec4b3",
   "metadata": {
    "executionCancelledAt": 1741643479047,
    "executionTime": 47,
    "lastExecutedAt": 1738028575805,
    "lastExecutedByKernel": "2eae4a5e-0e1a-4f98-b5a1-14e3fdc4c8e9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"
   },
   "outputs": [],
   "source": [
    "#you need to install torchmetrics and torch vision\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "662e1bf1-943f-4243-9fd4-02ce11609e8d",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": 1741643479049,
    "executionTime": 170,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1738028575975,
    "lastExecutedByKernel": "2eae4a5e-0e1a-4f98-b5a1-14e3fdc4c8e9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     },
     "2": {
      "height": 122,
      "type": "stream"
     },
     "3": {
      "height": 38,
      "type": "stream"
     },
     "4": {
      "height": 122,
      "type": "stream"
     },
     "5": {
      "height": 38,
      "type": "stream"
     },
     "6": {
      "height": 122,
      "type": "stream"
     },
     "7": {
      "height": 38,
      "type": "stream"
     },
     "8": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53c0a71d-d7d9-4a11-8a9b-55867ea7e0b5",
   "metadata": {
    "executionCancelledAt": 1741643479051,
    "executionTime": 54,
    "lastExecutedAt": 1738028576031,
    "lastExecutedByKernel": "2eae4a5e-0e1a-4f98-b5a1-14e3fdc4c8e9",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here    \n# Use as many cells as you need\nimages = train_data.data # This is a tensor of shape (60000, 28, 28)\nprint(\"images: \",images.shape)\nlabels = train_data.targets # This is a tensor of shape (60000,)\nprint(\"targets: \",labels.shape)\n\nunique_labels = set(labels.numpy())\nprint(unique_labels) #{1, 2, 3, 4, 5, 6, 7, 8, 9}\n\nimage = images[0]\nprint(image.shape)",
    "outputsMetadata": {
     "0": {
      "height": 101,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images:  torch.Size([60000, 28, 28])\n",
      "targets:  torch.Size([60000])\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Start coding here    \n",
    "# Use as many cells as you need\n",
    "images = train_data.data # This is a tensor of shape (60000, 28, 28)\n",
    "print(\"images: \",images.shape)\n",
    "labels = train_data.targets # This is a tensor of shape (60000,)\n",
    "print(\"targets: \",labels.shape)\n",
    "\n",
    "unique_labels = set(labels.numpy())\n",
    "print(unique_labels) #{1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
    "\n",
    "image = images[0] #select the first image\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e14cd3a4-2eba-4352-9109-f3e0a0f55872",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 122,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "\n",
    "# Ensure GPU is used if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Define the CNN Model\n",
    "class ProductTaggerCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Grayscale images (1 channel)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.classifier = nn.Linear(64 * 7 * 7, num_classes)  # Adjusted to match the output of the feature extractor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "#Initialize Model, Loss, Optimizer\n",
    "num_classes = 10  # Adjust based on dataset\n",
    "model = ProductTaggerCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#DataLoader (Replace with actual dataset)\n",
    "dataloader_train = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "dataloader_test = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "#Training Loop (1-2 epochs to keep runtime low)\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    for images, labels in dataloader_train:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#Evaluation and Storing Predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Metrics\n",
    "metric_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "# accuracy : Correct predictions / Total predictions = Measures overall correctness.\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=None).to(device)\n",
    "# precision : True Positives / (all predicted positive (both true and false))\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=None).to(device)\n",
    "# recall : True positives / (actual positives not just predicted) \n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        predictions.extend(preds.cpu().tolist())  #  Store predictions as a list\n",
    "        true_labels.extend(labels.cpu().tolist()) # labels is for the current batch, while true_labels holds the complete list of labels from the entire test set.\n",
    "\n",
    "        metric_accuracy.update(preds, labels) #update keep adding data \n",
    "        metric_precision.update(preds, labels)\n",
    "        metric_recall.update(preds, labels)\n",
    "\n",
    "#Compute Final Metrics\n",
    "accuracy = metric_accuracy.compute().item() # compute returns a tensor scalar and item convert it to python number\n",
    "precision = metric_precision.compute().tolist()\n",
    "recall = metric_recall.compute().tolist()\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
